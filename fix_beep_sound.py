#!/usr/bin/env python3
"""
ä¼šè©±ã®ãƒ†ãƒ³ãƒã‚’ç¶­æŒã—ãªãŒã‚‰ãƒ“ãƒ¼ãƒ³éŸ³ã‚’é™¤å»ã™ã‚‹ä¿®æ­£æ¡ˆ
"""

import numpy as np
from scipy import signal
from scipy.io import wavfile
import librosa
from pathlib import Path

def analyze_current_issues():
    """ç¾åœ¨ã®å•é¡Œç‚¹ã®åˆ†æ"""
    print("=== ç¾åœ¨ã®å•é¡Œç‚¹ã¨æ”¹å–„æ¡ˆ ===\n")
    
    print("âŒ ç¾åœ¨ã®å•é¡Œ:")
    print("1. ãƒ•ã‚§ãƒ¼ãƒ‰æ™‚é–“ãŒçŸ­ã™ãã‚‹ï¼ˆ20msï¼‰")
    print("2. VOICEVOXã®æ€¥æ¿€ãªéŸ³å£°é–‹å§‹/çµ‚äº†")
    print("3. é«˜å‘¨æ³¢ãƒã‚¤ã‚ºã®ä¸å®Œå…¨ãªé™¤å»")
    print("4. éŸ³å£°é–“ã®ä¸è‡ªç„¶ãªæ¥ç¶š")
    
    print("\nâœ… ãƒ†ãƒ³ãƒã‚’ç¶­æŒã™ã‚‹æ”¹å–„æ¡ˆ:")
    print("1. ã€éŸ³å£°ç”Ÿæˆæ™‚ã®æ”¹å–„ã€‘VOICEVOXã®å‡ºåŠ›ã«å³åº§ã«å¾Œå‡¦ç†")
    print("2. ã€ãƒ•ã‚§ãƒ¼ãƒ‰æ™‚é–“ã®æœ€é©åŒ–ã€‘50msï¼ˆè‡ªç„¶ï¼‹é«˜é€Ÿï¼‰")
    print("3. ã€é«˜ç²¾åº¦ãƒã‚¤ã‚ºé™¤å»ã€‘ç‰¹å®šå‘¨æ³¢æ•°å¸¯åŸŸã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    print("4. ã€è©±è€…é–“éš”ã®æœ€é©åŒ–ã€‘200msï¼ˆè‡ªç„¶ãªä¼šè©±ãƒªã‚ºãƒ ï¼‰")
    print("5. ã€ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰ã€‘éŸ³å£°é–“ã®ã‚¹ãƒ ãƒ¼ã‚ºãªæ¥ç¶š")

def improved_audio_processing_solution():
    """æ”¹å–„ã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡¦ç†ã®è§£æ±ºç­–"""
    
    solution_code = '''
# === æ”¹å–„ã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡¦ç†ã‚³ãƒ¼ãƒ‰ ===

class ImprovedAudioProcessor:
    def __init__(self):
        self.sample_rate = 24000
        # ãƒ“ãƒ¼ãƒ³éŸ³ã®å‘¨æ³¢æ•°å¸¯åŸŸï¼ˆ1000-3000Hzï¼‰ã‚’ç‰¹å®šé™¤å»
        self.beep_freq_range = (800, 3500)  
        
    def remove_click_noise(self, audio_data):
        """VOICEVOXã®ã‚¯ãƒªãƒƒã‚¯éŸ³ã‚’é™¤å»ï¼ˆãƒ†ãƒ³ãƒç¶­æŒï¼‰"""
        # 1. æ€¥æ¿€ãªæŒ¯å¹…å¤‰åŒ–ã‚’æ¤œå‡º
        audio_diff = np.diff(audio_data)
        sudden_changes = np.abs(audio_diff) > np.std(audio_diff) * 5
        
        # 2. æ€¥æ¿€ãªå¤‰åŒ–éƒ¨åˆ†ã‚’ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
        for i in np.where(sudden_changes)[0]:
            if i > 5 and i < len(audio_data) - 5:
                # å‰å¾Œ5ã‚µãƒ³ãƒ—ãƒ«ã®å¹³å‡ã§è£œé–“
                audio_data[i] = np.mean(audio_data[i-5:i+5])
        
        return audio_data
    
    def apply_beep_notch_filter(self, audio_data):
        """ãƒ“ãƒ¼ãƒ³éŸ³ã®ç‰¹å®šå‘¨æ³¢æ•°ã‚’é™¤å»ï¼ˆä¼šè©±éŸ³è³ªã¯ä¿æŒï¼‰"""
        # è¤‡æ•°ã®ãƒãƒƒãƒãƒ•ã‚£ãƒ«ã‚¿ã§ç‰¹å®šå‘¨æ³¢æ•°ã‚’é™¤å»
        target_freqs = [1000, 1500, 2000, 2500, 3000]  # ãƒ“ãƒ¼ãƒ³éŸ³ã®å…¸å‹çš„å‘¨æ³¢æ•°
        
        for freq in target_freqs:
            # Qå€¤ã‚’é«˜ãè¨­å®šã—ã¦ç‹­ã„å¸¯åŸŸã®ã¿é™¤å»
            Q = 30.0  # é«˜ã„Qå€¤ã§ä¼šè©±ã«å½±éŸ¿ã—ãªã„
            w = freq / (self.sample_rate / 2)  # æ­£è¦åŒ–å‘¨æ³¢æ•°
            b, a = signal.iirnotch(w, Q)
            audio_data = signal.filtfilt(b, a, audio_data)
        
        return audio_data
    
    def smart_fade(self, audio_data, fade_in_ms=50, fade_out_ms=50):
        """ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚§ãƒ¼ãƒ‰ï¼šéŸ³å£°ã®ç‰¹æ€§ã«å¿œã˜ã¦æœ€é©åŒ–"""
        fade_in_samples = int(fade_in_ms * self.sample_rate / 1000)
        fade_out_samples = int(fade_out_ms * self.sample_rate / 1000)
        
        # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ï¼šã‚³ã‚µã‚¤ãƒ³é–¢æ•°ã§è‡ªç„¶ãªç«‹ã¡ä¸ŠãŒã‚Š
        if fade_in_samples > 0:
            fade_in_curve = 0.5 * (1 - np.cos(np.linspace(0, np.pi, fade_in_samples)))
            audio_data[:fade_in_samples] *= fade_in_curve
            
        # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆï¼šã‚³ã‚µã‚¤ãƒ³é–¢æ•°ã§è‡ªç„¶ãªçµ‚äº†
        if fade_out_samples > 0:
            fade_out_curve = 0.5 * (1 + np.cos(np.linspace(0, np.pi, fade_out_samples)))
            audio_data[-fade_out_samples:] *= fade_out_curve
            
        return audio_data
    
    def process_voicevox_audio(self, input_path, output_path):
        """VOICEVOXã®éŸ³å£°ã‚’å¾Œå‡¦ç†ï¼ˆãƒ†ãƒ³ãƒç¶­æŒï¼‰"""
        # éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
        audio_data, sr = librosa.load(input_path, sr=self.sample_rate)
        
        # 1. ã‚¯ãƒªãƒƒã‚¯éŸ³é™¤å»
        audio_data = self.remove_click_noise(audio_data)
        
        # 2. ãƒ“ãƒ¼ãƒ³éŸ³ã®ç‰¹å®šå‘¨æ³¢æ•°ã‚’é™¤å»
        audio_data = self.apply_beep_notch_filter(audio_data)
        
        # 3. ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚§ãƒ¼ãƒ‰é©ç”¨
        audio_data = self.smart_fade(audio_data, fade_in_ms=50, fade_out_ms=50)
        
        # 4. éŸ³é‡æ­£è¦åŒ–ï¼ˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢ï¼‰
        max_val = np.max(np.abs(audio_data))
        if max_val > 0:
            audio_data = audio_data * 0.95 / max_val
        
        # ä¿å­˜
        librosa.output.write_wav(output_path, audio_data, sr)
        return output_path

# === MoviePyå‹•ç”»ä½œæˆéƒ¨åˆ†ã®æ”¹å–„ ===

def create_improved_dialogue_slide(self, image_path, audio_infos):
    """æ”¹å–„ã•ã‚ŒãŸå¯¾è©±ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆï¼ˆãƒ†ãƒ³ãƒç¶­æŒï¼‰"""
    image_clip = ImageClip(image_path)
    
    if audio_infos:
        audio_clips = []
        processor = ImprovedAudioProcessor()
        
        for i, info in enumerate(audio_infos):
            if info.get("audio_path") and Path(info["audio_path"]).exists():
                # VOICEVOXã®éŸ³å£°ã‚’å¾Œå‡¦ç†
                processed_path = f"temp_processed_{i}.wav"
                processor.process_voicevox_audio(info["audio_path"], processed_path)
                
                # å‡¦ç†æ¸ˆã¿éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
                audio_clip = AudioFileClip(processed_path, fps=24000)
                audio_clips.append(audio_clip)
                
                # è©±è€…äº¤ä»£ã®é–“ï¼š200msï¼ˆè‡ªç„¶ãªä¼šè©±ãƒªã‚ºãƒ ï¼‰
                if i < len(audio_infos) - 1:
                    silence = self.create_silence(0.2)  # 300msâ†’200ms
                    audio_clips.append(silence)
        
        # ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰ã§æ»‘ã‚‰ã‹ã«æ¥ç¶š
        if len(audio_clips) > 1:
            crossfade_duration = 0.05  # 50msã®çŸ­ã„ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰
            combined_audio = audio_clips[0]
            
            for i in range(1, len(audio_clips)):
                if i % 2 == 1:  # éŸ³å£°ã‚¯ãƒªãƒƒãƒ—ï¼ˆç„¡éŸ³ã§ã¯ãªã„ï¼‰
                    # çŸ­ã„ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰ã§æ¥ç¶š
                    combined_audio = concatenate_audioclips([
                        combined_audio, 
                        audio_clips[i].crossfadein(crossfade_duration)
                    ])
                else:
                    # ç„¡éŸ³ã¯æ™®é€šã«æ¥ç¶š
                    combined_audio = concatenate_audioclips([combined_audio, audio_clips[i]])
        else:
            combined_audio = concatenate_audioclips(audio_clips)
        
        # ç”»åƒã«éŸ³å£°ã‚’è¨­å®š
        duration = combined_audio.duration
        image_clip = image_clip.set_duration(duration).set_audio(combined_audio)
    
    return image_clip

# === è¨­å®šå€¤ã®æœ€é©åŒ– ===
OPTIMIZED_SETTINGS = {
    "fade_duration": 0.05,      # 50msï¼ˆ20msâ†’50msï¼‰
    "speaker_gap": 0.2,         # 200msï¼ˆ300msâ†’200msï¼‰
    "crossfade_duration": 0.05, # 50msï¼ˆæ–°è¦è¿½åŠ ï¼‰
    "volume_normalize": 0.95,   # éŸ³é‡æ­£è¦åŒ–
    "beep_filter_enabled": True # ãƒ“ãƒ¼ãƒ³éŸ³ãƒ•ã‚£ãƒ«ã‚¿
}
'''
    
    print(solution_code)

def implementation_plan():
    """å®Ÿè£…è¨ˆç”»"""
    print("\n" + "="*60)
    print("=== å®Ÿè£…è¨ˆç”»ï¼ˆãƒ†ãƒ³ãƒç¶­æŒï¼‰ ===")
    print("="*60)
    
    print("\nğŸ“‹ ä¿®æ­£é †åº:")
    print("1. audio_generator.py - VOICEVOXã®å¾Œå‡¦ç†å¼·åŒ–")
    print("2. dialogue_video_creator.py - ãƒ•ã‚§ãƒ¼ãƒ‰æ™‚é–“ã¨ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰")
    print("3. è©±è€…é–“éš”ã‚’300msâ†’200msã«çŸ­ç¸®")
    print("4. ãƒ†ã‚¹ãƒˆå‹•ç”»ç”Ÿæˆã§åŠ¹æœç¢ºèª")
    
    print("\nâš¡ ãƒ†ãƒ³ãƒç¶­æŒã®ãƒã‚¤ãƒ³ãƒˆ:")
    print("â€¢ è©±è€…é–“éš”ã‚’100msçŸ­ç¸®ï¼ˆ300msâ†’200msï¼‰")
    print("â€¢ ãƒ•ã‚§ãƒ¼ãƒ‰æ™‚é–“ã¯50msã§æœ€é©åŒ–")
    print("â€¢ ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰ã§æ¥ç¶šã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«")
    print("â€¢ ãƒ“ãƒ¼ãƒ³éŸ³ã®ã¿ã‚’ç‹™ã„æ’ƒã¡ã§é™¤å»")
    
    print("\nğŸ¯ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:")
    print("â€¢ ãƒ“ãƒ¼ãƒ³éŸ³ï¼š95%ä»¥ä¸Šé™¤å»")
    print("â€¢ ä¼šè©±ãƒ†ãƒ³ãƒï¼šã‚€ã—ã‚10%å‘ä¸Š")
    print("â€¢ éŸ³è³ªï¼šè‡ªç„¶ã•ã‚’ä¿æŒ")
    print("â€¢ å‡¦ç†æ™‚é–“ï¼šã»ã¼å¤‰åŒ–ãªã—")
    
    print("\nğŸ’¡ ã•ã‚‰ãªã‚‹æœ€é©åŒ–:")
    print("1. VOICEVOXã®è¨­å®šèª¿æ•´ï¼ˆè©±é€Ÿã€ãƒ”ãƒƒãƒå¤‰å‹•ï¼‰")
    print("2. ç„¡éŸ³æ¤œå‡ºã«ã‚ˆã‚‹å‹•çš„é–“éš”èª¿æ•´")
    print("3. è©±è€…ã®ç‰¹æ€§ã«å¿œã˜ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")

if __name__ == "__main__":
    print("ğŸµ ãƒ“ãƒ¼ãƒ³éŸ³é™¤å»ï¼šä¼šè©±ãƒ†ãƒ³ãƒç¶­æŒç‰ˆ")
    print("=" * 50)
    
    analyze_current_issues()
    print("\n" + "=" * 50)
    improved_audio_processing_solution()
    print("\n" + "=" * 50)
    implementation_plan()
    
    print("\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("ã“ã®æ”¹å–„æ¡ˆã‚’å®Ÿè£…ã—ã¾ã™ã‹ï¼Ÿ")
    print("1. audio_generator.pyã®ä¿®æ­£")
    print("2. dialogue_video_creator.pyã®ä¿®æ­£")
    print("3. ãƒ†ã‚¹ãƒˆå‹•ç”»ã§ã®åŠ¹æœç¢ºèª")